{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "from dataset_preprocessing import Paths, Dataset\n",
    "import datetime\n",
    "from gan import gradient_penalty_cond, Disc_ac_wgan_gp_1d, Gen_ac_wgan_gp_1d, initialize_weights\n",
    "from utils import MyDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dry_run = False\n",
    "if dry_run:\n",
    "    NUM_EPOCHS = 1\n",
    "else:\n",
    "    NUM_EPOCHS = 30\n",
    "BATCH_SIZE = 16\n",
    "CHANNELS_IMG = 1\n",
    "CRITIC_ITERATIONS = 5\n",
    "FEATURES_DISC = 120\n",
    "FEATURES_GEN = 120\n",
    "GEN_EMBEDDING = 100\n",
    "LAMBDA_GP = 10\n",
    "LEARNING_RATE = 1e-4\n",
    "Z_DIM = 100\n",
    "NUM_CLASSES = 20\n",
    "SEED = 42\n",
    "IMG_SIZE = 120\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "TRAIN_PATH = Paths.pandora_18k + 'Conv_models/Inception-V3/train_full_emb.csv'\n",
    "VALID_PATH = Paths.pandora_18k + 'Conv_models/Inception-V3/valid_full_emb.csv'\n",
    "FAKE_PATH = Paths.pandora_18k + 'Conv_models/Inception-V3/fake_cond_emb.csv'\n",
    "\n",
    "DIS_PATH = Paths.pandora_18k + 'Generation/model/dis_cond.pkl'\n",
    "GEN_PATH = Paths.pandora_18k + 'Generation/model/gen_cond.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "  \n",
    "df_train = pd.read_csv(TRAIN_PATH)\n",
    "df_valid = pd.read_csv(VALID_PATH)\n",
    "\n",
    "dataset_train = MyDataset(pd.concat([df_train, df_valid], axis=0), num_classes=NUM_CLASSES)\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset=dataset_train, \n",
    "                                        batch_size=BATCH_SIZE, \n",
    "                                        shuffle=True, \n",
    "                                        num_workers=4,\n",
    "                                        drop_last=True)\n",
    "\n",
    "dataset_valid = MyDataset(df_valid, num_classes=NUM_CLASSES)\n",
    "\n",
    "dataloader_valid = torch.utils.data.DataLoader(dataset=dataset_valid, \n",
    "                                        batch_size=BATCH_SIZE, \n",
    "                                        shuffle=True, \n",
    "                                        num_workers=4,\n",
    "                                        drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Gen_ac_wgan_gp_1d(Z_DIM, CHANNELS_IMG, FEATURES_GEN, NUM_CLASSES, IMG_SIZE, GEN_EMBEDDING).to(DEVICE)\n",
    "critic = Disc_ac_wgan_gp_1d(CHANNELS_IMG, FEATURES_DISC, NUM_CLASSES, IMG_SIZE).to(DEVICE)\n",
    "\n",
    "initialize_weights(gen)\n",
    "initialize_weights(critic)\n",
    "\n",
    "# initialize optimizer\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "opt_critic = optim.Adam(critic.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "gen.train()\n",
    "critic.train()\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "print((\"\\n\" + \"*\" * 50 + \"\\n\\t\\tstart time:      {0:02d}:{1:02d}:{2:02.0f}\\n\" + \"*\" * 50).format(\n",
    "    start_time.hour, start_time.minute, start_time.second))\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for batch_idx, (real, labels) in enumerate(dataloader_train):\n",
    "        real = real.to(DEVICE)\n",
    "        cur_batch_size = real.shape[0]\n",
    "        labels = labels.type(torch.LongTensor).to(DEVICE)\n",
    "\n",
    "        # Train Critic: max E[critic(real)] - E[critic(fake)]\n",
    "        # equivalent to minimizing the negative of that\n",
    "        for _ in range(CRITIC_ITERATIONS):\n",
    "            noise = torch.randn((cur_batch_size, Z_DIM, 1)).to(DEVICE)\n",
    "            fake = gen(noise, labels)\n",
    "            critic_real = critic(real, labels).reshape(-1)\n",
    "            critic_fake = critic(fake, labels).reshape(-1)\n",
    "            gp = gradient_penalty_cond(critic, labels, real, fake, device=DEVICE)\n",
    "            loss_critic = (\n",
    "                    -(torch.mean(critic_real) - torch.mean(critic_fake)) + LAMBDA_GP * gp\n",
    "            )\n",
    "            critic.zero_grad()\n",
    "            loss_critic.backward(retain_graph=True)\n",
    "            opt_critic.step()\n",
    "\n",
    "            ### Train Generaor: max E[critic(gen_fake)] â†” min -E[critic(gen_fake)]\n",
    "            gen_fake = critic(fake, labels).reshape(-1)\n",
    "            loss_gen = -torch.mean(gen_fake)\n",
    "            gen.zero_grad()\n",
    "            loss_gen.backward()\n",
    "            opt_gen.step()\n",
    "\n",
    "        # Print losses occasionally and print to tensorboard\n",
    "        if batch_idx % 200 == 0:\n",
    "            now = datetime.datetime.now()\n",
    "            print(\"{}\".format(now.strftime(\"%d - %H:%M:%S\")), end=\"      \")\n",
    "            print(\n",
    "                f\"Epoch [{epoch:3d} / {NUM_EPOCHS:3d}]      Batch {batch_idx:4d}/{len(dataloader_train):5d} \\\n",
    "                     Loss D: {loss_critic: 6.4f},\\tloss G: {loss_gen:6.4f}\"\n",
    "            )\n",
    "\n",
    "# save model\n",
    "torch.save(gen.state_dict(), GEN_PATH)\n",
    "torch.save(critic.state_dict(), DIS_PATH)\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "print(\"\\ntotal elapsed time: {}\".format(now - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
