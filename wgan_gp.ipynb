{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch import optim\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "from dataset_preprocessing import Paths, Dataset\n",
    "from gan import gradient_penalty, Disc_dcgan_gp_1d, Gen_dcgan_gp_1d, initialize_weights\n",
    "from utils import MyDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dry_run = False\n",
    "\n",
    "ds = Dataset(Paths.pandora_18k)\n",
    "\n",
    "if dry_run:\n",
    "    NUM_EPOCHS = 1\n",
    "else:\n",
    "    NUM_EPOCHS = 50\n",
    "BATCH_SIZE = 16\n",
    "CRITIC_ITERATIONS = 5\n",
    "CHANNELS_IMG = 1\n",
    "IMAGE_SIZE = 120\n",
    "FEATURES_DISC = 120\n",
    "FEATURES_GEN = 120\n",
    "LEARNING_RATE = 1e-4\n",
    "LAMBDA_GP = 10\n",
    "Z_DIM = 100\n",
    "NUM_CLASSES = 20\n",
    "SEED = 42\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "TRAIN_PATH = Paths.pandora_18k + 'Conv_models/Inception-V3/train_full_emb.csv'\n",
    "VALID_PATH = Paths.pandora_18k + 'Conv_models/Inception-V3/valid_full_emb.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "\n",
    "for i, cl in enumerate(ds.classes):\n",
    "\n",
    "    FAKE_PATH = Paths.pandora_18k + 'Conv_models/Inception-V3/fake_emb_' + cl + '.csv'\n",
    "    DIS_PATH = Paths.pandora_18k + 'Generation/model/dis_' + cl + '.pkl'\n",
    "    GEN_PATH = Paths.pandora_18k + 'Generation/model/gen_' + cl + '.pkl'\n",
    "        \n",
    "    df_train = pd.read_csv(TRAIN_PATH)\n",
    "    df_train = df_train.query(f\"label == {i+1}\")\n",
    "    df_valid = pd.read_csv(VALID_PATH)\n",
    "    df_valid = df_valid.query(f\"label == {i+1}\")\n",
    "   \n",
    "\n",
    "    dataset_train = MyDataset(pd.concat([df_train, df_valid], axis=0), num_classes=NUM_CLASSES)\n",
    "\n",
    "    dataloader_train = torch.utils.data.DataLoader(dataset=dataset_train, \n",
    "                                            batch_size=BATCH_SIZE, \n",
    "                                            shuffle=True, \n",
    "                                            num_workers=4,\n",
    "                                            drop_last=True)\n",
    "\n",
    "    gen = Gen_dcgan_gp_1d(Z_DIM, CHANNELS_IMG, FEATURES_GEN).to(DEVICE)\n",
    "    dis = Disc_dcgan_gp_1d(CHANNELS_IMG, FEATURES_DISC).to(DEVICE)\n",
    "\n",
    "    initialize_weights(gen)\n",
    "    initialize_weights(dis)\n",
    "\n",
    "    opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "    opt_critic = optim.Adam(dis.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "\n",
    "    gen.train()\n",
    "    dis.train()\n",
    "\n",
    "    start_time = datetime.datetime.now()\n",
    "    print((\"\\n\" + \"*\" * 50 + \"\\n\\t\\tstart time:      {0:02d}:{1:02d}:{2:02.0f}\\n\" + \"*\" * 50).format(\n",
    "        start_time.hour, start_time.minute, start_time.second))\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        # Target labels not needed! <3 unsupervised\n",
    "        for batch_idx, (real, _) in enumerate(dataloader_train):\n",
    "            real = real.to(DEVICE)\n",
    "\n",
    "            for _ in range(CRITIC_ITERATIONS):\n",
    "                noise = torch.randn((BATCH_SIZE, Z_DIM, 1)).to(DEVICE)\n",
    "                fake = gen(noise)\n",
    "                dis_real = dis(real).reshape(-1)\n",
    "                dis_fake = dis(fake).reshape(-1)\n",
    "                gp = gradient_penalty(dis, real, fake, device=DEVICE)\n",
    "                loss_dis = (\n",
    "                        -(torch.mean(dis_real) - torch.mean(dis_fake)) + LAMBDA_GP * gp\n",
    "                )\n",
    "                dis.zero_grad()\n",
    "                loss_dis.backward(retain_graph=True)\n",
    "                opt_critic.step()\n",
    "\n",
    "                ### Train Generaor: min -E[critic(gen_fake)]\n",
    "                output = dis(fake).reshape(-1)\n",
    "                loss_gen = -torch.mean(output)\n",
    "                gen.zero_grad()\n",
    "                loss_gen.backward()\n",
    "                opt_gen.step()\n",
    "\n",
    "            # Print losses occasionally and print to tensorboard\n",
    "            if batch_idx % 100 == 0:\n",
    "                t_now = datetime.datetime.now()\n",
    "                print(\n",
    "                    f\"{t_now.hour:02d}:{t_now.minute:02d}:{t_now.second:02d}     Epoch [{epoch: 3d} / {NUM_EPOCHS: 3d}]    Batch {batch_idx: 4d}/{len(dataloader_train): 5d} \\\n",
    "                        Loss D: {loss_dis: .4f}, loss G: {loss_gen:.4f}\"\n",
    "                )\n",
    "\n",
    "    # save model\n",
    "    torch.save(gen.state_dict(), GEN_PATH)\n",
    "    torch.save(dis.state_dict(), DIS_PATH)\n",
    "\n",
    "    now = datetime.datetime.now()\n",
    "    print(\"\\ntotal elapsed time: {}\".format(now - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
