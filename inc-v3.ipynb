{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import logging\n",
    "import os\n",
    "from sklearn.metrics import f1_score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from conv_model import Model\n",
    "from dataset_preprocessing import Paths, Dataset, Dataloader, Dataloader_parts\n",
    "from metrics import confusion_matrix, accuracy, accuracy_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, weight=None, \n",
    "                 gamma=2., reduction='none'):\n",
    "        nn.Module.__init__(self)\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        \n",
    "    def forward(self, input_tensor, target_tensor):\n",
    "        log_prob = F.log_softmax(input_tensor, dim=-1)\n",
    "        prob = torch.exp(log_prob)\n",
    "        return F.nll_loss(\n",
    "            ((1 - prob) ** self.gamma) * log_prob, \n",
    "            target_tensor, \n",
    "            weight=self.weight,\n",
    "            reduction = self.reduction\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    \"\"\"Parameters of training process\"\"\"\n",
    "\n",
    "    training_mode = False\n",
    "\n",
    "    #dataset parameters\n",
    "    pandora_18k = Dataset(path_to_the_dataset=Paths.pandora_18k)\n",
    "    num_classes = pandora_18k.number_of_classes\n",
    "    batch_size = 24\n",
    "\n",
    "    train_lu = Paths.pandora_18k + \"Train_lu/\"\n",
    "    train_ld = Paths.pandora_18k + \"Train_ld/\"\n",
    "    train_ru = Paths.pandora_18k + \"Train_ru/\"\n",
    "    train_rd = Paths.pandora_18k + \"Train_rd/\"\n",
    "    train_c = Paths.pandora_18k + \"Train_c/\"\n",
    "\n",
    "    valid_lu = Paths.pandora_18k + \"Validation_lu/\"\n",
    "    valid_ld = Paths.pandora_18k + \"Validation_ld/\"\n",
    "    valid_ru = Paths.pandora_18k + \"Validation_ru/\"\n",
    "    valid_rd = Paths.pandora_18k + \"Validation_rd/\"\n",
    "    valid_c = Paths.pandora_18k + \"Validation_c/\"\n",
    "\n",
    "    test_lu = Paths.pandora_18k + \"Test_lu/\"\n",
    "    test_ld = Paths.pandora_18k + \"Test_ld/\"\n",
    "    test_ru = Paths.pandora_18k + \"Test_ru/\"\n",
    "    test_rd = Paths.pandora_18k + \"Test_rd/\"\n",
    "    test_c = Paths.pandora_18k + \"Test_c/\"\n",
    "\n",
    "\n",
    "    #device\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    #logging\n",
    "    logging_file = \"logs/inception_v3.log\"\n",
    "\n",
    "    #model paths\n",
    "    model_path = Paths.pandora_18k + 'Conv_models/Inception-V3/'\n",
    "    model_save_path = model_path + 'inc_v3_model.pth' \n",
    "\n",
    "    #model initialization parameters\n",
    "    model_init_kwargs = {\n",
    "\n",
    "    'device' : device,\n",
    "    'num_classes' : num_classes,\n",
    "\n",
    "    #convolutional network basic parameters\n",
    "    'conv_name' : 'Inception-V3',\n",
    "    'conv_model' : models.inception_v3(weights='IMAGENET1K_V1'),\n",
    "    'input_shape' :  (299, 299)\n",
    "\n",
    "    }\n",
    "    \n",
    "    #model training parameters\n",
    "    model_training_kwargs = {\n",
    "\n",
    "    'device' : device,\n",
    "    'num_epochs' : 45,\n",
    "    'criterion' : (nn.CrossEntropyLoss(), 'Cross-Entropy'), \n",
    "\n",
    "    #optimizer parameters\n",
    "    'optimizer' : (optim.SGD, 'SGD'),\n",
    "    'learn_rate' :  0.0002,\n",
    "    'momentum' :  0.888,\n",
    "    'nesterov' : True,\n",
    "    #scheduler parameters\n",
    "    'scheduler' : lr_scheduler.StepLR,\n",
    "    'step_size' :  10,\n",
    "    'gamma' :  0.9\n",
    "    }\n",
    "\n",
    "    #probability vectors paths\n",
    "    prb_vec_train = model_path + 'train.csv'\n",
    "    prb_vec_valid = model_path + 'valid.csv'\n",
    "    prb_vec_test = model_path + 'test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Training.pandora_18k.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "cudnn.benchmark = False\n",
    "logging.basicConfig(level=logging.INFO, filename=Training.logging_file,filemode=\"a\",\n",
    "                    format=\"%(asctime)s %(levelname)s %(message)s\")\n",
    "\n",
    "model = Model(Training.model_init_kwargs)\n",
    "\n",
    "dataloader = Dataloader(model, Training.pandora_18k.train_path, Training.pandora_18k.val_path, Training.pandora_18k.test_path, Training.batch_size)\n",
    "\n",
    "if Training.training_mode:\n",
    "\n",
    "    Training.model_training_kwargs['dataloader'] = dataloader\n",
    "\n",
    "    model = model.fit(Training.model_training_kwargs)\n",
    "\n",
    "    torch.save(model.conv_nn.state_dict(), Training.model_save_path)\n",
    "\n",
    "else:\n",
    "    conv_nn = Training.model_init_kwargs.get('conv_model')                                                                                                                                                                                                                                                                                                                                         \n",
    "    conv_nn.load_state_dict(torch.load(Training.model_save_path))\n",
    "    conv_nn.eval()\n",
    "\n",
    "    model.conv_nn = conv_nn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total accuracy Ð¸ accuracy per each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, target = model.predict(device=Training.device, dataiter=iter(dataloader.dataloaders['test']), classes=Training.pandora_18k.classes)\n",
    "\n",
    "print(f'Total accuracy: {accuracy(pred, target):.1f} %')\n",
    "\n",
    "acc_per_class = accuracy_per_class(pred, target, Training.pandora_18k.classes)\n",
    "\n",
    "for style, acc in acc_per_class.items():\n",
    "    print(f'Accuracy for {style}: {acc:.1f} %')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean min-3 accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sorted(list(acc_per_class.items()), key=lambda x : x[1])[:3]\n",
    "\n",
    "print(f\"Mean accuracy for min 3 styles : {sum([el[1] for el in x]) / 3:.1f} %\")\n",
    "\n",
    "for style, acc in x:\n",
    "    print(f'Accuracy for {style}: {acc:.1f} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
