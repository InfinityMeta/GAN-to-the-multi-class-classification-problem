{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.linalg import sqrtm\n",
    "from dataset_preprocessing import Paths, Dataset\n",
    "import plotly.express as px\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import logging\n",
    "import random\n",
    "from metrics import confusion_matrix, accuracy_per_class\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.optim import lr_scheduler, Adam\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import copy\n",
    "from utils import MyDataset, FocalLoss\n",
    "from gan import Gen_ac_wgan_gp_1d, Gen_dcgan_gp_1d\n",
    "from snn import ShallowNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNELS_IMG = 1\n",
    "FEATURES_GEN = 120\n",
    "Z_DIM = 100\n",
    "BATCH_SIZE = 16\n",
    "IMG_SIZE = 120\n",
    "GEN_EMBEDDING = 100\n",
    "NUM_CLASSES = 20\n",
    "BATCH_SIZE_SNN = 64\n",
    "EPOCHS = 20\n",
    "\n",
    "LOGGING_FILE = \"logs/cases.log\"\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_v3_path =  Paths.pandora_18k + 'Conv_models/Inception-V3/'\n",
    "\n",
    "ds = Dataset(Paths.pandora_18k)\n",
    "\n",
    "train_path = inc_v3_path + 'train_full_emb.csv'\n",
    "valid_path = inc_v3_path + 'valid_full_emb.csv'\n",
    "test_path = inc_v3_path + 'test_full_emb.csv'\n",
    "\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_valid = pd.read_csv(valid_path)\n",
    "df_test = pd.read_csv(test_path)\n",
    "\n",
    "df = shuffle(pd.concat([df_train, df_valid], axis=0))\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, filename=LOGGING_FILE,filemode=\"a\",\n",
    "                    format=\"%(asctime)s %(levelname)s %(message)s\")\n",
    "\n",
    "classes = ds.classes\n",
    "\n",
    "snn_path = inc_v3_path + 'snn.pth'\n",
    "\n",
    "dataset_valid = MyDataset(df_valid, num_classes=len(ds.classes))\n",
    "\n",
    "dataset_test = MyDataset(df_test, num_classes=len(ds.classes))\n",
    "\n",
    "\n",
    "dataset_valid = MyDataset(df_valid, num_classes=len(ds.classes))\n",
    "\n",
    "dataloader_valid = torch.utils.data.DataLoader(dataset=dataset_valid, \n",
    "                                        batch_size=BATCH_SIZE_SNN, \n",
    "                                        shuffle=True, \n",
    "                                        num_workers=4,\n",
    "                                        drop_last=True)\n",
    "\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset=dataset_test, \n",
    "                                        batch_size=BATCH_SIZE_SNN, \n",
    "                                        shuffle=True, \n",
    "                                        num_workers=4,\n",
    "                                        drop_last=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WGAN generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "filter_need = False\n",
    "\n",
    "fake_vectors = pd.DataFrame()\n",
    "fake_vectors_filtered = pd.DataFrame()\n",
    "\n",
    "gen_classes = range(20)\n",
    "\n",
    "for ind in gen_classes:\n",
    "\n",
    "    cl = classes[ind]\n",
    "\n",
    "    gen_path = Paths.pandora_18k + 'Generation/model/gen_' + cl + '.pkl'\n",
    "    gen_path_filtered = Paths.pandora_18k + 'Generation/model/gen_' + cl + '_filtered.pkl'\n",
    "\n",
    "    gen = Gen_dcgan_gp_1d(Z_DIM, CHANNELS_IMG, FEATURES_GEN)\n",
    "    gen_filtered = Gen_dcgan_gp_1d(Z_DIM, CHANNELS_IMG, FEATURES_GEN, filtered=True)\n",
    "\n",
    "    gen.load_state_dict(torch.load(gen_path))\n",
    "    gen_filtered.load_state_dict(torch.load(gen_path_filtered))\n",
    "    \n",
    "    gen.to(DEVICE)\n",
    "    gen_filtered.to(DEVICE)\n",
    "\n",
    "    df_cl = df.query(f\"label == {ind+1}\")\n",
    "\n",
    "\n",
    "    valid_cl = df_valid.query(f\"label == {ind+1}\")\n",
    "\n",
    "    if filter_need:\n",
    "        filtering = torch.tensor(valid_cl.mean())[range(ind*6, (ind+1)*6)]\n",
    "    else:\n",
    "        filtering = torch.zeros(6)\n",
    "\n",
    "    cl_fake_vectors = pd.DataFrame()\n",
    "    cl_fake_vectors_filtered = pd.DataFrame()\n",
    "\n",
    "    while(len(cl_fake_vectors) < len(df_cl) // 2):\n",
    "\n",
    "        noise = torch.randn((BATCH_SIZE, Z_DIM, 1)).to(DEVICE)\n",
    "\n",
    "        fake = gen(noise).squeeze()\n",
    "\n",
    "        fake_ind = []\n",
    "\n",
    "        for i in range(len(fake)):\n",
    "\n",
    "            if all(torch.abs(fake[i].detach().cpu()[range(ind*6, (ind+1)*6)] - filtering) >  0.0):\n",
    "                fake_ind.append(i)\n",
    "\n",
    "        cl_fake_vectors = pd.concat([cl_fake_vectors, pd.DataFrame(data=fake[fake_ind].detach().cpu())])\n",
    "\n",
    "    cl_fake_vectors[\"label\"] = pd.Series([ind+1 for _ in range(len(cl_fake_vectors))])\n",
    "    cl_fake_vectors.columns = df.columns\n",
    "    fake_vectors = pd.concat([fake_vectors, cl_fake_vectors])\n",
    "    \n",
    "    while(len(cl_fake_vectors_filtered) < len(df_cl) // 2):\n",
    "\n",
    "        noise = torch.randn((BATCH_SIZE, Z_DIM, 1)).to(DEVICE)\n",
    "\n",
    "        fake_filtered = gen_filtered(noise).squeeze()\n",
    "\n",
    "        fake_filtered_ind = []\n",
    "\n",
    "        for i in range(len(fake_filtered)):\n",
    "\n",
    "            if all(torch.abs(fake_filtered[i].detach().cpu()[range(ind*6, (ind+1)*6)] - filtering) > 0.0):\n",
    "                fake_filtered_ind.append(i)\n",
    "\n",
    "        cl_fake_vectors_filtered = pd.concat([cl_fake_vectors_filtered, pd.DataFrame(data=fake_filtered[fake_filtered_ind].detach().cpu())])\n",
    "\n",
    "    cl_fake_vectors_filtered[\"label\"] = pd.Series([ind+1 for _ in range(len(cl_fake_vectors_filtered))])\n",
    "    cl_fake_vectors_filtered.columns = df.columns\n",
    "    fake_vectors_filtered = pd.concat([fake_vectors_filtered, cl_fake_vectors_filtered])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conditional WGAN Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_fake_vectors = pd.DataFrame()\n",
    "cond_fake_vectors_filtered = pd.DataFrame()\n",
    "\n",
    "gen_cond_path = Paths.pandora_18k + 'Generation/model/gen_cond.pkl'\n",
    "gen_cond_f_path = Paths.pandora_18k + 'Generation/model/gen_cond_filtered.pkl'\n",
    "\n",
    "gen_cond = Gen_ac_wgan_gp_1d(Z_DIM, CHANNELS_IMG, FEATURES_GEN, NUM_CLASSES, IMG_SIZE, GEN_EMBEDDING).to(DEVICE)\n",
    "gen_cond_filtered = Gen_ac_wgan_gp_1d(Z_DIM, CHANNELS_IMG, FEATURES_GEN, NUM_CLASSES, IMG_SIZE, GEN_EMBEDDING, filtered=True).to(DEVICE)\n",
    "\n",
    "gen_cond.load_state_dict(torch.load(gen_cond_path))\n",
    "gen_cond_filtered.load_state_dict(torch.load(gen_cond_f_path))\n",
    "\n",
    "gen_cond.to(DEVICE)\n",
    "gen_cond_filtered.to(DEVICE)\n",
    "\n",
    "gen_cond.eval()\n",
    "gen_cond_filtered.eval()\n",
    "\n",
    "for ind, _ in enumerate(classes):\n",
    "\n",
    "    cl_fake_vectors = pd.DataFrame()\n",
    "    cl_fake_vectors_filtered = pd.DataFrame()\n",
    "\n",
    "    df_cl = df.query(f\"label == {ind+1}\")\n",
    "\n",
    "    for _ in range(len(df_cl) // BATCH_SIZE):\n",
    "\n",
    "        noise = torch.randn((BATCH_SIZE, Z_DIM, 1)).to(DEVICE)\n",
    "        labels = torch.tensor([ind for _ in range(BATCH_SIZE)])\n",
    "        labels = labels.type(torch.LongTensor).to(DEVICE)\n",
    "\n",
    "        fake = gen_cond(noise, labels)\n",
    "        fake_filtered = gen_cond_filtered(noise, labels)\n",
    "\n",
    "        cl_fake_vectors = pd.concat([cl_fake_vectors, pd.DataFrame(data=fake.detach().cpu().squeeze())])\n",
    "        cl_fake_vectors_filtered = pd.concat([cl_fake_vectors_filtered, pd.DataFrame(data=fake_filtered.detach().cpu().squeeze())])\n",
    "\n",
    "    cl_fake_vectors[\"label\"] = pd.Series([ind+1 for _ in range(len(cl_fake_vectors))])\n",
    "    cl_fake_vectors_filtered[\"label\"] = pd.Series([ind+1 for _ in range(len(cl_fake_vectors_filtered))])\n",
    "\n",
    "    cl_fake_vectors.columns = cl_fake_vectors_filtered.columns = df.columns\n",
    "\n",
    "    cond_fake_vectors = pd.concat([cond_fake_vectors, cl_fake_vectors.iloc[:len(df_cl) // 2]])\n",
    "    cond_fake_vectors_filtered = pd.concat([cond_fake_vectors_filtered, cl_fake_vectors_filtered.iloc[:len(df_cl) // 2]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments with not filtered vectors with WGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = MyDataset(shuffle(pd.concat([df, \n",
    "                                             fake_vectors.query(\"label == 6\"), \n",
    "                                             fake_vectors.query(\"label == 10\"), \n",
    "                                             fake_vectors.query(\"label == 11\"), \n",
    "                                             ], \n",
    "                                             axis=0)), num_classes=len(ds.classes))\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset=dataset_train, \n",
    "                                        batch_size=BATCH_SIZE_SNN, \n",
    "                                        shuffle=True, \n",
    "                                        num_workers=4,\n",
    "                                        drop_last=True)\n",
    "\n",
    "dataloaders = {\"train\" : dataloader_train, \"validation\" : dataloader_valid, \"test\" : dataloader_test}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 121\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "logging.info(f\"Seed {SEED}\")\n",
    "\n",
    "Net = ShallowNN().to(DEVICE)\n",
    "\n",
    "optimizer_name = \"Adam\"\n",
    "\n",
    "lr = 0.003\n",
    "\n",
    "criterion_name = \"FocalLoss\"\n",
    "\n",
    "optimizer = Adam(Net.parameters(), lr=lr, capturable=True)\n",
    "\n",
    "criterion = FocalLoss(reduction=\"mean\", gamma=2)\n",
    "\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\")\n",
    "\n",
    "logging.info(f\"Net parameters {Net.parameters}\")\n",
    "logging.info(f\"Optimizer :{optimizer_name}, lr : {lr}, criterion : {criterion_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "\n",
    "statistics_data = {\n",
    "            'number of epochs' : range(1,EPOCHS+1),\n",
    "            'training loss' : [],\n",
    "            'validation loss' : [],\n",
    "            'training accuracy' : [],\n",
    "            'validation accuracy' : []\n",
    "        }\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "best_acc = 0.0\n",
    "best_model_wts = copy.deepcopy(Net.state_dict())\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    print(f'Epoch {epoch}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and validation phase\n",
    "    for phase in ['train', 'validation']:\n",
    "        if phase == 'train':\n",
    "            Net.train()  # Set model to training mode\n",
    "        else:\n",
    "            Net.eval()   # Set model to evaluate mode\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Iterate over data.\n",
    "        with tqdm(dataloaders[phase], unit='batch') as tepoch:\n",
    "            for inputs, labels in tepoch:\n",
    "                tepoch.set_description(f\"Epoch {epoch}\")\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                labels = labels.type(torch.LongTensor).to(DEVICE)\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = torch.squeeze(Net(inputs))\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step(0.005)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            if phase == 'train':\n",
    "                statistics_data['training loss'].append(epoch_loss)\n",
    "                statistics_data['training accuracy'].append(epoch_acc.cpu().numpy())\n",
    "            else:\n",
    "                statistics_data['validation loss'].append(epoch_loss)\n",
    "                statistics_data['validation accuracy'].append(epoch_acc.cpu().numpy())\n",
    "\n",
    "            if phase == 'validation' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(Net.state_dict())\n",
    "            \n",
    "            print(f'{phase} loss : {epoch_loss:.4f} {phase} accuracy: {epoch_acc*100:.2f}%')\n",
    "            logging.info(f'{phase} loss : {epoch_loss:.4f} {phase} accuracy: {epoch_acc*100:.2f}%')\n",
    "\n",
    "        print()\n",
    "\n",
    "time_elapsed = time.time() - start_time\n",
    "print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "logging.info(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "print(f'Best validation accuracy: {best_acc*100:.2f}%')\n",
    "logging.info(f'Best validation accuracy: {best_acc*100:.2f}%')\n",
    "\n",
    "Net.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.tensor([], dtype=torch.int32).to(DEVICE)\n",
    "pred = torch.tensor([], dtype=torch.int32).to(DEVICE)\n",
    "\n",
    "for images, labels in dataloaders[\"test\"]:\n",
    "    images = images.to(DEVICE)\n",
    "    labels = labels.to(DEVICE)\n",
    "\n",
    "    target = torch.cat((target, labels))\n",
    "\n",
    "    outputs = Net(images)\n",
    "    _, predictions = torch.max(outputs, 2)\n",
    "    predictions = torch.squeeze(predictions, 1)\n",
    "\n",
    "    pred = torch.cat((pred, predictions))\n",
    "\n",
    "target, pred = target.to(torch.int32).cpu(), pred.to(torch.int32).cpu()\n",
    "\n",
    "print(f\"Accuracy : {round(accuracy_score(target, pred) * 100, 3)} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_per_class = accuracy_per_class(pred, target, ds.classes)\n",
    "\n",
    "for style, acc in acc_per_class.items():\n",
    "    print(f'Accuracy for {style}: {acc:.1f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sorted(list(acc_per_class.items()), key=lambda x : x[1])[:3]\n",
    "\n",
    "print(f\"Mean accuracy for min 3 styles : {sum([el[1] for el in x]) / 3:.1f} %\")\n",
    "\n",
    "for style, acc in x:\n",
    "    print(f'Accuracy for {style}: {acc:.1f} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
