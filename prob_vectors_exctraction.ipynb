{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/noonmare/anaconda3/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/noonmare/anaconda3/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from dataset_preprocessing import Paths, Dataset\n",
    "from utils import CROPP_FUNCS, TRAIN_PARTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset(path_to_the_dataset=Paths.pandora_18k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = False\n",
    "\n",
    "HEIGHT = WIDTH = 299\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize((WIDTH, HEIGHT)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "model_path = Paths.pandora_18k + 'Conv_models/Inception-V3/inc_v3_model.pth'\n",
    "model_path_lu = Paths.pandora_18k + 'Conv_models/Inception-V3/inc_v3_model_lu.pth'\n",
    "model_path_ru = Paths.pandora_18k + 'Conv_models/Inception-V3/inc_v3_model_ru.pth'\n",
    "model_path_c = Paths.pandora_18k + 'Conv_models/Inception-V3/inc_v3_model_c.pth'\n",
    "model_path_ld = Paths.pandora_18k + 'Conv_models/Inception-V3/inc_v3_model_ld.pth'\n",
    "model_path_rd = Paths.pandora_18k + 'Conv_models/Inception-V3/inc_v3_model_rd.pth'\n",
    "\n",
    "conv_nn = models.inception_v3(weights='IMAGENET1K_V1')\n",
    "num_features = conv_nn.fc.in_features\n",
    "conv_nn.fc = nn.Linear(num_features, len(ds.classes))\n",
    "conv_nn.aux_logits=False                                                                                                                                                                                                                                                                                                                                        \n",
    "conv_nn.load_state_dict(torch.load(model_path))\n",
    "conv_nn.eval()\n",
    "\n",
    "conv_nn.to(device)\n",
    "\n",
    "conv_nn_lu = models.inception_v3(weights='IMAGENET1K_V1')\n",
    "num_features = conv_nn_lu.fc.in_features\n",
    "conv_nn_lu.fc = nn.Linear(num_features, len(ds.classes))\n",
    "conv_nn_lu.aux_logits=False                                                                                                                                                                                                                                                                                                                                        \n",
    "conv_nn_lu.load_state_dict(torch.load(model_path_lu))\n",
    "conv_nn_lu.eval()\n",
    "\n",
    "conv_nn_lu.to(device)\n",
    "\n",
    "conv_nn_ru = models.inception_v3(weights='IMAGENET1K_V1')\n",
    "num_features = conv_nn_ru.fc.in_features\n",
    "conv_nn_ru.fc = nn.Linear(num_features, len(ds.classes))\n",
    "conv_nn_ru.aux_logits=False                                                                                                                                                                                                                                                                                                                                        \n",
    "conv_nn_ru.load_state_dict(torch.load(model_path_ru))\n",
    "conv_nn_ru.eval()\n",
    "\n",
    "conv_nn_ru.to(device)\n",
    "\n",
    "conv_nn_c = models.inception_v3(weights='IMAGENET1K_V1')\n",
    "num_features = conv_nn_c.fc.in_features\n",
    "conv_nn_c.fc = nn.Linear(num_features, len(ds.classes))\n",
    "conv_nn_c.aux_logits=False                                                                                                                                                                                                                                                                                                                                        \n",
    "conv_nn_c.load_state_dict(torch.load(model_path_c))\n",
    "conv_nn_c.eval()\n",
    "\n",
    "conv_nn_c.to(device)\n",
    "\n",
    "conv_nn_ld = models.inception_v3(weights='IMAGENET1K_V1')\n",
    "num_features = conv_nn_ld.fc.in_features\n",
    "conv_nn_ld.fc = nn.Linear(num_features, len(ds.classes))\n",
    "conv_nn_ld.aux_logits=False                                                                                                                                                                                                                                                                                                                                        \n",
    "conv_nn_ld.load_state_dict(torch.load(model_path_ld))\n",
    "conv_nn_ld.eval()\n",
    "\n",
    "conv_nn_ld.to(device)\n",
    "\n",
    "conv_nn_rd = models.inception_v3(weights='IMAGENET1K_V1')\n",
    "num_features = conv_nn_rd.fc.in_features\n",
    "conv_nn_rd.fc = nn.Linear(num_features, len(ds.classes))\n",
    "conv_nn_rd.aux_logits=False                                                                                                                                                                                                                                                                                                                                        \n",
    "conv_nn_rd.load_state_dict(torch.load(model_path_rd))\n",
    "conv_nn_rd.eval()\n",
    "\n",
    "conv_nn_rd.to(device)\n",
    "\n",
    "cropp_funcs_cnns = [(CROPP_FUNCS[\"lu\"], conv_nn_lu), (CROPP_FUNCS[\"ru\"], conv_nn_ru), (CROPP_FUNCS[\"ld\"], conv_nn_ld), (CROPP_FUNCS[\"rd\"], conv_nn_rd), (CROPP_FUNCS[\"c\"], conv_nn_c), (lambda im : Image.open(im).convert(\"RGB\"), conv_nn)]\n",
    "\n",
    "columns = []\n",
    "\n",
    "parts = [\"lu\", \"ru\", \"ld\", \"rd\", \"c\", \"full\"]\n",
    "\n",
    "for p in parts:\n",
    "    for c in ds.classes:\n",
    "        columns.append(c + '_' + p)\n",
    "\n",
    "columns.append(\"label\")\n",
    "\n",
    "train_emb = pd.DataFrame(columns=columns)\n",
    "valid_emb = pd.DataFrame(columns=columns)\n",
    "test_emb = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "for tp in TRAIN_PARTS:\n",
    "    path = Paths.pandora_18k + tp + '/'\n",
    "    for ind, cl in enumerate(ds.classes):\n",
    "        cl_path = path + cl + '/'\n",
    "        cl_imgs = os.listdir(cl_path)\n",
    "        for img_name in cl_imgs:\n",
    "            img_path = cl_path + img_name\n",
    "            parts_probs = []\n",
    "            for cr_func, cnn in cropp_funcs_cnns:\n",
    "                timg = cr_func(img_path)\n",
    "                timg = torch.unsqueeze(img_transform(timg), 0).to(device)\n",
    "                output = cnn(timg)\n",
    "                probs = softmax(output)\n",
    "                parts_probs.append(probs)   \n",
    "            prob_emb = reduce(lambda x, y: torch.cat([x, y], axis=1), parts_probs).tolist()[0] + [ind+1]\n",
    "            if tp == \"Train\":\n",
    "                train_emb.loc[len(train_emb)] = prob_emb\n",
    "            if tp == \"Validation\":\n",
    "                valid_emb.loc[len(valid_emb)] = prob_emb\n",
    "            if tp == \"Test\":\n",
    "                test_emb.loc[len(test_emb)] = prob_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = []\n",
    "\n",
    "for c in ds.classes:\n",
    "    for p in parts:\n",
    "        new_columns.append(c + '_' + p)\n",
    "\n",
    "new_columns.append(\"label\")\n",
    "\n",
    "train_emb = train_emb[new_columns]\n",
    "valid_emb = valid_emb[new_columns]\n",
    "test_emb = test_emb[new_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_v3_path =  Paths.pandora_18k + 'Conv_models/Inception-V3/'\n",
    "\n",
    "train_emb_path = inc_v3_path + 'train_full_emb.csv'\n",
    "valid_emb_path = inc_v3_path + 'valid_full_emb.csv'\n",
    "test_emb_path = inc_v3_path + 'test_full_emb.csv'\n",
    "\n",
    "train_emb.to_csv(train_emb_path, index=False)\n",
    "valid_emb.to_csv(valid_emb_path, index=False)\n",
    "test_emb.to_csv(test_emb_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
